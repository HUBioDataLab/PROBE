{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook calculates similarity and error between protein embeddings and use GO semantic similarity as gold standart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from multiprocessing import Manager, Pool\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load protein vectors of Gene2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['Gene', 'Vector'] \n",
    "representationFile = '/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/representation_vectors/Learned_Embeddings/learned_embed_calculated_human_protein_vectors.csv'\n",
    "LearnedVec = pd.read_csv(representationFile,delimiter=',',encoding='utf-8', names=colnames, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_float_list(stringList):\n",
    "    l2 = stringList.strip(\"[\").strip(\"]\").split(',')\n",
    "    result = list(map(float, l2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnedVec['Vector'] = LearnedVec['Vector'].map(string_to_float_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Gene names</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A584</td>\n",
       "      <td>TVBK2_HUMAN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>T cell receptor beta variable 11-2</td>\n",
       "      <td>TRBV11-2 TCRBV21S3A2N2T</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>115</td>\n",
       "      <td>3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9BXU3</td>\n",
       "      <td>TX13A_HUMAN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Testis-expressed protein 13A</td>\n",
       "      <td>TEX13A</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>409</td>\n",
       "      <td>2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q15031</td>\n",
       "      <td>SYLM_HUMAN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Probable leucine--tRNA ligase, mitochondrial (...</td>\n",
       "      <td>LARS2 KIAA0028</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>903</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q6PKC3</td>\n",
       "      <td>TXD11_HUMAN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Thioredoxin domain-containing protein 11 (EF-h...</td>\n",
       "      <td>TXNDC11 EFP1</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>985</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P42681</td>\n",
       "      <td>TXK_HUMAN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>Tyrosine-protein kinase TXK (EC 2.7.10.2) (Pro...</td>\n",
       "      <td>TXK PTK4 RLK</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>527</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry   Entry name    Status  \\\n",
       "0  A0A584  TVBK2_HUMAN  reviewed   \n",
       "1  Q9BXU3  TX13A_HUMAN  reviewed   \n",
       "2  Q15031   SYLM_HUMAN  reviewed   \n",
       "3  Q6PKC3  TXD11_HUMAN  reviewed   \n",
       "4  P42681    TXK_HUMAN  reviewed   \n",
       "\n",
       "                                       Protein names               Gene names  \\\n",
       "0                 T cell receptor beta variable 11-2  TRBV11-2 TCRBV21S3A2N2T   \n",
       "1                       Testis-expressed protein 13A                   TEX13A   \n",
       "2  Probable leucine--tRNA ligase, mitochondrial (...           LARS2 KIAA0028   \n",
       "3  Thioredoxin domain-containing protein 11 (EF-h...             TXNDC11 EFP1   \n",
       "4  Tyrosine-protein kinase TXK (EC 2.7.10.2) (Pro...             TXK PTK4 RLK   \n",
       "\n",
       "               Organism  Length  Annotation  \n",
       "0  Homo sapiens (Human)     115  3 out of 5  \n",
       "1  Homo sapiens (Human)     409  2 out of 5  \n",
       "2  Homo sapiens (Human)     903  5 out of 5  \n",
       "3  Homo sapiens (Human)     985  5 out of 5  \n",
       "4  Homo sapiens (Human)     527  5 out of 5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNIPROT data for mapping between UNIPROT accession numbers and UNIPROT entry names\n",
    "uniprot_metadata_directory = \"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/Uniprot/\"\n",
    "uniprot_metadata_file_path = uniprot_metadata_directory + \"uniprot_human_all.tab\"\n",
    "uniprot_vars = ['Entry','Entry name','Status','Protein names','Gene names','Organism','Length','Annotation' ]\n",
    "uniprot_df = pd.read_csv(uniprot_metadata_file_path, sep='\\t')\n",
    "uniprot_df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TX13A_HUMAN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein1 = \"Q9BXU3\"\n",
    "prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "prot1name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearnedVec_GenesList = LearnedVec['Gene'].tolist()\n",
    "len(LearnedVec_GenesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.asarray(LearnedVec.query(\"Gene == '1433B_HUMAN'\")['Vector'].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P31946'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eName = '1433B_HUMAN'\n",
    "uniprot_df[uniprot_df['Entry name'] == eName]['Entry'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261b3567b30e45738e80253cfb4fa99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20421), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LearnedVecDF = pd.DataFrame(columns=['Entry', 'Vector'])\n",
    "for i, row in tqdm_notebook(LearnedVec.iterrows(), total=len(LearnedVec_GenesList)):\n",
    "    gene =  row['Gene']\n",
    "    entry = uniprot_df[uniprot_df['Entry name'] == gene]['Entry'].item()\n",
    "    vector = row['Vector']\n",
    "    LearnedVecDF.loc[i] = [entry,vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P31946</td>\n",
       "      <td>[0.1206292550840799, 0.042524608591712997, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P62258</td>\n",
       "      <td>[0.0865170389789406, 0.06565096681950155, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q04917</td>\n",
       "      <td>[0.03067628642963321, 0.08261820964118351, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P61981</td>\n",
       "      <td>[0.056176401725012974, 0.1272234897543238, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P31947</td>\n",
       "      <td>[0.09433241449567525, 0.05418153837457671, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P27348</td>\n",
       "      <td>[-0.007474015609202146, 0.12553591556421906, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P63104</td>\n",
       "      <td>[0.04930505288580744, 0.05025088669477938, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P30443</td>\n",
       "      <td>[-0.09634417381379114, 0.18386099284089832, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P01892</td>\n",
       "      <td>[-0.11567174365089174, 0.18178789219098315, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P04439</td>\n",
       "      <td>[-0.12398412279961105, 0.2040801817622601, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry                                             Vector\n",
       "0  P31946  [0.1206292550840799, 0.042524608591712997, -0....\n",
       "1  P62258  [0.0865170389789406, 0.06565096681950155, -0.0...\n",
       "2  Q04917  [0.03067628642963321, 0.08261820964118351, -0....\n",
       "3  P61981  [0.056176401725012974, 0.1272234897543238, -0....\n",
       "4  P31947  [0.09433241449567525, 0.05418153837457671, -0....\n",
       "5  P27348  [-0.007474015609202146, 0.12553591556421906, -...\n",
       "6  P63104  [0.04930505288580744, 0.05025088669477938, -0....\n",
       "7  P30443  [-0.09634417381379114, 0.18386099284089832, 0....\n",
       "8  P01892  [-0.11567174365089174, 0.18178789219098315, 0....\n",
       "9  P04439  [-0.12398412279961105, 0.2040801817622601, 0.0..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearnedVecDF[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnedVecDF.to_csv(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/embedding_dataframes/LearnedVec_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearnedVecDF.to_pickle(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/representation_vectors/representation_vector_dataframes/learned_vec.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This part was used to be sure parallel and sequential versions gives same results\\ncosine_distance_list1 = []\\nreal_distance_list1 = []\\n\\nsimilarityMatrixFileName = \"\"\\nsimilarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\\n\\nhuman_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\\nhuman_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\\n\\nproteinListTmp = human_proteinSimilarityMatrix.columns[0:10]\\nfor i,protein1 in tqdm_notebook(enumerate(proteinListTmp)):\\n    for j in range(len(proteinListTmp)):\\n        if j>i:\\n            protein2 = proteinListTmp[j]\\n            #print((protein1,protein2))\\n            prot1name = uniprot_df.query(\"Entry == @protein1\")[\\'Entry name\\'].item()\\n            prot2name = uniprot_df.query(\"Entry == @protein2\")[\\'Entry name\\'].item()\\n            #if protein1 in LearnedVec_GenesList and protein2 in LearnedVec_GenesList:\\n            prot1vec = np.asarray(LearnedVec.query(\"Gene == @prot1name\")[\\'Vector\\'].item())\\n            prot2vec = np.asarray(LearnedVec.query(\"Gene == @prot2name\")[\\'Vector\\'].item())\\n            #cosine will return in shape of input vectors first dimension\\n            cosine_dist = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\\n            cosine_norm = (1+cosine_dist)/2\\n            cosine_distance_list1.append(cosine_norm)\\n            real_distance_list1.append(human_proteinSimilarityMatrix.loc[protein1,protein2])\\n\\nprint(len(cosine_distance_list1))\\nprint(mse(real_distance_list1,cosine_distance_list1))\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This part was used to be sure parallel and sequential versions gives same results\n",
    "cosine_distance_list1 = []\n",
    "real_distance_list1 = []\n",
    "\n",
    "similarityMatrixFileName = \"\"\n",
    "similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\n",
    "\n",
    "human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "human_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\n",
    "\n",
    "proteinListTmp = human_proteinSimilarityMatrix.columns[0:10]\n",
    "for i,protein1 in tqdm_notebook(enumerate(proteinListTmp)):\n",
    "    for j in range(len(proteinListTmp)):\n",
    "        if j>i:\n",
    "            protein2 = proteinListTmp[j]\n",
    "            #print((protein1,protein2))\n",
    "            prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "            prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()\n",
    "            #if protein1 in LearnedVec_GenesList and protein2 in LearnedVec_GenesList:\n",
    "            prot1vec = np.asarray(LearnedVec.query(\"Gene == @prot1name\")['Vector'].item())\n",
    "            prot2vec = np.asarray(LearnedVec.query(\"Gene == @prot2name\")['Vector'].item())\n",
    "            #cosine will return in shape of input vectors first dimension\n",
    "            cosine_dist = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "            cosine_norm = (1+cosine_dist)/2\n",
    "            cosine_distance_list1.append(cosine_norm)\n",
    "            real_distance_list1.append(human_proteinSimilarityMatrix.loc[protein1,protein2])\n",
    "\n",
    "print(len(cosine_distance_list1))\n",
    "print(mse(real_distance_list1,cosine_distance_list1))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Multiprocess check\\nproteinList = []\\nmanager = Manager()\\nsimilarity_list = manager.list()\\n\\ndef parallelSimilarity(paramList):\\n    #print(paramList)\\n    i = paramList[0]\\n    j = paramList[1]\\n    if j>i:  \\n        protein1 = proteinList[i]\\n        protein2 = proteinList[j]\\n        prot1name = uniprot_df.query(\"Entry == @protein1\")[\\'Entry name\\'].item()\\n        prot2name = uniprot_df.query(\"Entry == @protein2\")[\\'Entry name\\'].item()\\n        prot1vec = protVecEmbeddingDict[()][prot1name]\\n        prot2vec = protVecEmbeddingDict[()][prot2name]\\n        #cosine will return in shape of input vectors first dimension\\n        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\\n        real = human_protienSimilarityMatrix.loc[protein1,protein2]\\n        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\\n        similarity_list.append((real,cos))\\n\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\\nsimilarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\\n\\nhuman_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\\nhuman_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\\nproteinList = human_protienSimilarityMatrix.columns[0:10]\\n\\ni = range(len(proteinList))\\nj = range(len(proteinList))\\nprotParamList = list(itertools.product(i,j))\\n\\n    #manager = Manager()\\n    #similarity_list = manager.list()\\ntotal_task_num=len(proteinList)**2\\n\\npool = Pool()\\npool.map(parallelSimilarity, protParamList)\\npool.close()\\npool.join()\\n\\nreal_distance_list = [value[0] for value in similarity_list]\\ncosine_distance_list = [value[1] for value in similarity_list]\\n\\nmseValue = mse(real_distance_list,cosine_distance_list)\\nprint(mseValue)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Multiprocess check\n",
    "proteinList = []\n",
    "manager = Manager()\n",
    "similarity_list = manager.list()\n",
    "\n",
    "def parallelSimilarity(paramList):\n",
    "    #print(paramList)\n",
    "    i = paramList[0]\n",
    "    j = paramList[1]\n",
    "    if j>i:  \n",
    "        protein1 = proteinList[i]\n",
    "        protein2 = proteinList[j]\n",
    "        prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "        prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()\n",
    "        prot1vec = protVecEmbeddingDict[()][prot1name]\n",
    "        prot2vec = protVecEmbeddingDict[()][prot2name]\n",
    "        #cosine will return in shape of input vectors first dimension\n",
    "        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "        real = human_protienSimilarityMatrix.loc[protein1,protein2]\n",
    "        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\n",
    "        similarity_list.append((real,cos))\n",
    "\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\n",
    "similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\n",
    "\n",
    "human_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "human_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\n",
    "proteinList = human_protienSimilarityMatrix.columns[0:10]\n",
    "\n",
    "i = range(len(proteinList))\n",
    "j = range(len(proteinList))\n",
    "protParamList = list(itertools.product(i,j))\n",
    "\n",
    "    #manager = Manager()\n",
    "    #similarity_list = manager.list()\n",
    "total_task_num=len(proteinList)**2\n",
    "\n",
    "pool = Pool()\n",
    "pool.map(parallelSimilarity, protParamList)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "real_distance_list = [value[0] for value in similarity_list]\n",
    "cosine_distance_list = [value[1] for value in similarity_list]\n",
    "\n",
    "mseValue = mse(real_distance_list,cosine_distance_list)\n",
    "print(mseValue)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity_list and proteinList as global variables\n",
    "proteinList = []\n",
    "manager = Manager()\n",
    "similarity_list = manager.list()\n",
    "proteinListNew = manager.list()\n",
    "\n",
    "def parallelSimilarity(paramList):\n",
    "    i = paramList[0]\n",
    "    j = paramList[1] \n",
    "    aspect = paramList[2]\n",
    "    if j>i:\n",
    "        protein1 = proteinListNew[i]\n",
    "        protein2 = proteinListNew[j]     \n",
    "        prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "        prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()     \n",
    "        prot1vec = np.asarray(LearnedVec.query(\"Gene == @prot1name\")['Vector'].item())\n",
    "        prot2vec = np.asarray(LearnedVec.query(\"Gene == @prot2name\")['Vector'].item())\n",
    "        #cosine will return in shape of input vectors first dimension\n",
    "        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "        manhattanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'cityblock')\n",
    "        manhattanDistNorm = manhattanDist/(norm(prot1vec,1) + norm(prot2vec,1))\n",
    "        euclideanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'euclidean')\n",
    "        euclideanDistNorm = euclideanDist/(norm(prot1vec,2) + norm(prot2vec,2)) \n",
    "        #print([(prot1name,prot2name),(prot1vec,prot2vec)])\n",
    "        #print((prot1name,prot2name))\n",
    "        #print()\n",
    "        #print((cos,euclideanDist,norm(prot1vec,2),norm(prot2vec,2)))\n",
    "        real = paramList[3]\n",
    "        #real = human_protienSimilarityMatrix.loc[protein1,protein2]\n",
    "        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\n",
    "        #Similarity = 1-distance\n",
    "        similarity_list.append((real,1-cos,1-manhattanDistNorm.item(),1-euclideanDistNorm.item()))\n",
    "    return similarity_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity values with parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_distance_list = []\n",
    "cosine_distance_list = []\n",
    "euclidian_distance_list = []\n",
    "\n",
    "def calculateMSEforOntology(aspect,sparse=False):\n",
    "    \n",
    "    #Clear lists before each aspect\n",
    "    similarity_list[:] = []\n",
    "    proteinListNew[:] = []\n",
    "\n",
    "    #similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\n",
    "    similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+\\\n",
    "    aspect+\"_proteinSimilarityMatrix_for_highest_annotated_200_proteins.csv\"\n",
    "\n",
    "    \n",
    "    human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "    human_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\n",
    "    proteinList = human_proteinSimilarityMatrix.columns\n",
    "    \n",
    "    #proteinListNew is referanced using Manager\n",
    "    for prot in proteinList:\n",
    "        proteinListNew.append(prot)\n",
    "        \n",
    "    if sparse:\n",
    "        #sparsified_similarities = np.load(\"SparsifiedSimilarites_for_highest_500.npy\")\n",
    "        sparsified_similarity_coordinates = np.load(\"SparsifiedSimilarityCoordinates_\"+aspect+\"_for_highest_500.npy\")\n",
    "        protParamList = sparsified_similarity_coordinates\n",
    "    else:     \n",
    "        i = range(len(proteinList))\n",
    "        j = range(len(proteinList))\n",
    "        protParamList = list(itertools.product(i,j))\n",
    "    protParamListNew = []\n",
    "    # Prepare parameters for parallel processing these parameters will be \n",
    "    # used concurrently by different processes\n",
    "    for tup in tqdm_notebook(protParamList):\n",
    "        i = tup[0]\n",
    "        j = tup[1]\n",
    "        \n",
    "        if sparse:\n",
    "            protein1 = proteinListNew[i]\n",
    "            protein2 = proteinListNew[j]\n",
    "            real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "            tupNew = (tup[0],tup[1],aspect,real)\n",
    "            protParamListNew.append(tupNew)\n",
    "        else:\n",
    "            if j > i:\n",
    "                protein1 = proteinListNew[i]\n",
    "                protein2 = proteinListNew[j]\n",
    "                real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "                tupNew = (tup[0],tup[1],aspect,real)\n",
    "                protParamListNew.append(tupNew)\n",
    "\n",
    "    total_task_num=len(protParamListNew)\n",
    "    pool = Pool()\n",
    "    similarity_listRet = []\n",
    "    for similarity_listRet in tqdm_notebook(pool.imap_unordered(parallelSimilarity, protParamListNew), total=total_task_num):\n",
    "        pass\n",
    "    real_distance_list = [value[0] for value in similarity_listRet]\n",
    "    cosine_distance_list = [value[1] for value in similarity_listRet]\n",
    "    manhattan_distance_list = [value[2] for value in similarity_listRet]\n",
    "    euclidian_distance_list = [value[3] for value in similarity_listRet]\n",
    "\n",
    "    #mseValue = mse(real_distance_list,cosine_distance_list)\n",
    "    cosineCorr = spearmanr(real_distance_list, cosine_distance_list)\n",
    "    manhattanCorr = spearmanr(real_distance_list, manhattan_distance_list)\n",
    "    euclidianCorr = spearmanr(real_distance_list, euclidian_distance_list)\n",
    "    \n",
    "    random.seed(42)\n",
    "    random_list = []\n",
    "    for i in range(len(real_distance_list)):\n",
    "        random_list.append(random.uniform(0, 1))\n",
    "    \n",
    "    if sparse:\n",
    "        cosine_randomCorr = spearmanr(cosine_distance_list, random_list)\n",
    "        manhattan_randomCorr = spearmanr(manhattan_distance_list, random_list)\n",
    "        euclidian_randomCorr = spearmanr(euclidian_distance_list, random_list)\n",
    "        print(\"Cosine Random Correlation for \"+aspect+\" is \" + str(cosine_randomCorr))\n",
    "        print(\"Manhattan Random Correlation for \"+aspect+\" is \" + str(manhattan_randomCorr))\n",
    "        print(\"Euclidian Random Correlation for \"+aspect+\" is \" + str(euclidian_randomCorr))\n",
    "      \n",
    "    print(\"Cosine Correlation for \"+aspect+\" is \" + str(cosineCorr))\n",
    "    print(\"Manhattan Correlation for \"+aspect+\" is \" + str(manhattanCorr))\n",
    "    print(\"Euclidian Correlation for \"+aspect+\" is \" + str(euclidianCorr))\n",
    "\n",
    "    #return (cosine_distance_list,manhattan_distance_list,euclidian_distance_list)\n",
    "\n",
    "    \n",
    "    if sparse:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr,cosine_randomCorr,manhattan_randomCorr,euclidian_randomCorr)\n",
    "    else:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59079874b524c918a2a37d591e0976b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e55c04925424fc0b17d91d1076df4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for MF is SpearmanrResult(correlation=-0.2401017901513225, pvalue=6.523584505513545e-259)\n",
      "Manhattan Correlation for MF is SpearmanrResult(correlation=0.2503067046108497, pvalue=6.147398899937215e-282)\n",
      "Euclidian Correlation for MF is SpearmanrResult(correlation=0.2401017901514139, pvalue=6.523584502488044e-259)\n",
      "(SpearmanrResult(correlation=-0.2401017901513225, pvalue=6.523584505513545e-259), SpearmanrResult(correlation=0.2503067046108497, pvalue=6.147398899937215e-282), SpearmanrResult(correlation=0.2401017901514139, pvalue=6.523584502488044e-259))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cb7bbbbf69406c9ba1c89cf0076ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128643ae7365405bb8b753b129dcb823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for BP is SpearmanrResult(correlation=-0.15863480297908533, pvalue=2.6726065060063238e-112)\n",
      "Manhattan Correlation for BP is SpearmanrResult(correlation=0.14337665824409587, pvalue=7.036197229742844e-92)\n",
      "Euclidian Correlation for BP is SpearmanrResult(correlation=0.15863480297908533, pvalue=2.6726065060063238e-112)\n",
      "(SpearmanrResult(correlation=-0.15863480297908533, pvalue=2.6726065060063238e-112), SpearmanrResult(correlation=0.14337665824409587, pvalue=7.036197229742844e-92), SpearmanrResult(correlation=0.15863480297908533, pvalue=2.6726065060063238e-112))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6aca46c340d4fc284320b2d2c0d0a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e523059e554e66887fc6d1be481601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for CC is SpearmanrResult(correlation=-0.028530847547553053, pvalue=5.689356569503309e-05)\n",
      "Manhattan Correlation for CC is SpearmanrResult(correlation=0.009651732466011226, pvalue=0.17335870257584748)\n",
      "Euclidian Correlation for CC is SpearmanrResult(correlation=0.028530847547553053, pvalue=5.689356569503309e-05)\n",
      "(SpearmanrResult(correlation=-0.028530847547553053, pvalue=5.689356569503309e-05), SpearmanrResult(correlation=0.009651732466011226, pvalue=0.17335870257584748), SpearmanrResult(correlation=0.028530847547553053, pvalue=5.689356569503309e-05))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dl = calculateMSEforOntology(\"MF\")\\nimport matplotlib.pyplot\\nmatplotlib.pyplot.hist(dl[0])\\nmatplotlib.pyplot.hist(dl[1])\\nmatplotlib.pyplot.hist(dl[2])'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal \\n\"\n",
    "#saveFileName = \"SimilarityLearnedEmbeddingVec.csv\"\n",
    "saveFileName = \"SimilarityLearnedEmbeddingVec_highest_200.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect)  \n",
    "    print(corr)\n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    # Python will convert \\n to os.linesep\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "# 0.3673674654105104 mse for MF with 0:10\n",
    "# 0.31965355246378196 mse for BP with 0:10\n",
    "# 0.29460915219361683 mse for CC with 0:10\n",
    "'''dl = calculateMSEforOntology(\"MF\")\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.hist(dl[0])\n",
    "matplotlib.pyplot.hist(dl[1])\n",
    "matplotlib.pyplot.hist(dl[2])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbuffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal,random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\\n#saveFileName = \"SimilarityGene2Vec.csv\"\\nsaveFileName = \"Similarity_Sparse_LearnedEmbeddingVec_highest_500.csv\"\\nf = open(saveFileName,\\'w\\')\\nf.write(buffer)\\n\\nfor aspect in [\"MF\",\"BP\",\"CC\"]:\\n    corr = calculateMSEforOntology(aspect,True) \\n    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \\n    f = open(saveFileName,\\'a\\')\\n    f.write(buffer) #Give your csv text here.\\n    ## Python will convert \\n to os.linesep\\n    f.close()\\n    \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal\\\n",
    ",random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\n",
    "#saveFileName = \"SimilarityGene2Vec.csv\"\n",
    "saveFileName = \"Similarity_Sparse_LearnedEmbeddingVec_highest_500.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect,True) \n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    ## Python will convert \\n to os.linesep\n",
    "    f.close()\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
