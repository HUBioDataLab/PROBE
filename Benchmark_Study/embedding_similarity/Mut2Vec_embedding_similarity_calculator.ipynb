{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook calculates similarity and error between protein embeddings and use GO semantic similarity as gold standart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from multiprocessing import Manager, Pool\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['Gene', 'Vector'] \n",
    "representationFile = '/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/representation_vectors/Mut2Vec/Mut2Vec+PI+R_ENSG.txt'\n",
    "Mut2Vec = pd.read_csv(representationFile,delimiter=' ',encoding='utf-8', names=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_ids_path = '/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/Mut2Vec/ensemble_ids.txt'\n",
    "#Mut2Vec[0].to_csv(ensemble_ids_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['Ensemble_ID', 'Translate', 'Entry','Entry_name','Status','Protein_names','Gene_names','Organism','Length'] \n",
    "ensemble2gene_file = \"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/Uniprot/ensembl2uniprot.tab\"\n",
    "ensemble2gene = pd.read_csv(ensemble2gene_file,delimiter='\\t',encoding='utf-8',names=colnames, header=None,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc0a8e6d8af4ab7b042fb2e3f8d7f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18584), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Mut2Vec_dataframe = pd.DataFrame(columns = ['Gene', 'Entry', 'Vector'])\n",
    "\n",
    "for index, row in tqdm_notebook(Mut2Vec.iterrows(), total = len(Mut2Vec)):\n",
    "    gene_id = row[0]\n",
    "    protein_entry = ensemble2gene.loc[ensemble2gene['Ensemble_ID'] == gene_id]['Entry']\n",
    "    protein_id = \"\"\n",
    "    if len(protein_entry) >= 1:\n",
    "        protein_id = list(protein_entry)[0]\n",
    "    gene_vector = list(row[1:301])\n",
    "    Mut2Vec_dataframe = Mut2Vec_dataframe.append({'Gene': gene_id,'Entry':protein_id,'Vector':gene_vector},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Mut2Vec_dataframe.iloc[0]['Vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mut2Vec_dataframe.to_pickle(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/representation_vectors/representation_vector_dataframes/mut2vec_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mut2Vec_dataframe.to_csv(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/Mut2Vec/mut2vec_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIPROT data for mapping between UNIPROT accession numbers and UNIPROT entry names\n",
    "uniprot_metadata_directory = \"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/Uniprot/\"\n",
    "uniprot_metadata_file_path = uniprot_metadata_directory + \"uniprot_human_all.tab\"\n",
    "uniprot_vars = ['Entry','Entry name','Status','Protein names','Gene names','Organism','Length','Annotation' ]\n",
    "uniprot_df = pd.read_csv(uniprot_metadata_file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mut2VecProteinList = list(set(Mut2Vec_dataframe['Entry']))\n",
    "Mut2VecProteinList.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This part was used to be sure parallel and sequential versions gives same results\\ncosine_distance_list1 = []\\nreal_distance_list1 = []\\n\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\\n\\nhuman_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\\nhuman_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\\n\\nproteinListTmp = human_proteinSimilarityMatrix.columns[0:10]\\nfor i,protein1 in tqdm_notebook(enumerate(proteinListTmp)):\\n    for j in range(len(proteinListTmp)):\\n        if j>i:\\n            protein2 = proteinListTmp[j]\\n            if protein1 in Mut2VecProteinList and protein2 in Mut2VecProteinList:\\n                \\n                prot1vec = np.asarray(Mut2Vec_dataframe.query(\"Protein_Entry == @protein1\")[\\'Vector\\'].item())\\n                prot2vec = np.asarray(Mut2Vec_dataframe.query(\"Protein_Entry == @protein2\")[\\'Vector\\'].item())\\n                #cosine will return in shape of input vectors first dimension\\n                cosine_dist = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\\n                cosine_norm = (1+cosine_dist)/2\\n                cosine_distance_list1.append(cosine_norm)\\n                real_distance_list1.append(human_proteinSimilarityMatrix.loc[protein1,protein2])\\n\\nprint(len(cosine_distance_list1))\\nprint(spearmanr(real_distance_list1,cosine_distance_list1))\\n\\n\\n# MF    0.1866509691526721\\n# BP    0.3116883116883117\\n# CC   -0.2711730421384723\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This part was used to be sure parallel and sequential versions gives same results\n",
    "cosine_distance_list1 = []\n",
    "real_distance_list1 = []\n",
    "\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\n",
    "\n",
    "human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "human_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\n",
    "\n",
    "proteinListTmp = human_proteinSimilarityMatrix.columns[0:10]\n",
    "for i,protein1 in tqdm_notebook(enumerate(proteinListTmp)):\n",
    "    for j in range(len(proteinListTmp)):\n",
    "        if j>i:\n",
    "            protein2 = proteinListTmp[j]\n",
    "            if protein1 in Mut2VecProteinList and protein2 in Mut2VecProteinList:\n",
    "                \n",
    "                prot1vec = np.asarray(Mut2Vec_dataframe.query(\"Protein_Entry == @protein1\")['Vector'].item())\n",
    "                prot2vec = np.asarray(Mut2Vec_dataframe.query(\"Protein_Entry == @protein2\")['Vector'].item())\n",
    "                #cosine will return in shape of input vectors first dimension\n",
    "                cosine_dist = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "                cosine_norm = (1+cosine_dist)/2\n",
    "                cosine_distance_list1.append(cosine_norm)\n",
    "                real_distance_list1.append(human_proteinSimilarityMatrix.loc[protein1,protein2])\n",
    "\n",
    "print(len(cosine_distance_list1))\n",
    "print(spearmanr(real_distance_list1,cosine_distance_list1))\n",
    "\n",
    "\n",
    "# MF    0.1866509691526721\n",
    "# BP    0.3116883116883117\n",
    "# CC   -0.2711730421384723\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity_list and proteinList as global variables\n",
    "proteinList = []\n",
    "manager = Manager()\n",
    "similarity_list = manager.list()\n",
    "proteinListNew = manager.list()\n",
    "\n",
    "def parallelSimilarity(paramList):\n",
    "    i = paramList[0]\n",
    "    j = paramList[1] \n",
    "    aspect = paramList[2]\n",
    "    if j>i:\n",
    "        protein1 = proteinListNew[i]\n",
    "        protein2 = proteinListNew[j]\n",
    "        if protein1 in Mut2VecProteinList and protein2 in Mut2VecProteinList:\n",
    "            prot1vec = np.asarray(Mut2Vec_dataframe.query(\"Entry == @protein1\")['Vector'].item())\n",
    "            prot2vec = np.asarray(Mut2Vec_dataframe.query(\"Entry == @protein2\")['Vector'].item())\n",
    "            #print(str(protein1) + str(prot1vec))\n",
    "            #print(str(protein2) + str(prot2vec))\n",
    "            #cosine will return in shape of input vectors first dimension\n",
    "            cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "            manhattanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'cityblock')\n",
    "            manhattanDistNorm = manhattanDist/(norm(prot1vec,1) + norm(prot2vec,1))\n",
    "            euclideanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'euclidean')\n",
    "            euclideanDistNorm = euclideanDist/(norm(prot1vec,2) + norm(prot2vec,2)) \n",
    "            real = paramList[3]\n",
    "            #real = human_protienSimilarityMatrix.loc[protein1,protein2]\n",
    "            # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\n",
    "            similarity_list.append((real,1-cos,1-manhattanDistNorm.item(),1-euclideanDistNorm.item()))\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMSEforOntology(aspect,sparse=False):\n",
    "    \n",
    "    #Clear lists before each aspect\n",
    "    similarity_list[:] = []\n",
    "    proteinListNew[:] = []\n",
    "\n",
    "    #similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\n",
    "    similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"\\\n",
    "    +aspect+\"_proteinSimilarityMatrix_for_highest_annotated_200_proteins.csv\"\n",
    "\n",
    "    human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "    human_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\n",
    "    proteinList = human_proteinSimilarityMatrix.columns\n",
    "    \n",
    "    #proteinListNew is referanced using Manager\n",
    "    for prot in proteinList:\n",
    "        proteinListNew.append(prot)\n",
    "    if sparse:\n",
    "        #sparsified_similarities = np.load(\"SparsifiedSimilarites_for_highest_500.npy\")\n",
    "        sparsified_similarity_coordinates = np.load(\"SparsifiedSimilarityCoordinates_\"+aspect+\"_for_highest_500.npy\")\n",
    "        protParamList = sparsified_similarity_coordinates\n",
    "    else:     \n",
    "        i = range(len(proteinList))\n",
    "        j = range(len(proteinList))\n",
    "        protParamList = list(itertools.product(i,j))\n",
    "    protParamListNew = []\n",
    "    # Prepare parameters for parallel processing these parameters will be \n",
    "    # used concurrently by different processes\n",
    "    for tup in tqdm_notebook(protParamList):\n",
    "        i = tup[0]\n",
    "        j = tup[1]\n",
    "        \n",
    "        if sparse:\n",
    "            protein1 = proteinListNew[i]\n",
    "            protein2 = proteinListNew[j]\n",
    "            real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "            tupNew = (tup[0],tup[1],aspect,real)\n",
    "            protParamListNew.append(tupNew)\n",
    "        else:\n",
    "            if j > i:\n",
    "                protein1 = proteinListNew[i]\n",
    "                protein2 = proteinListNew[j]\n",
    "                real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "                tupNew = (tup[0],tup[1],aspect,real)\n",
    "                protParamListNew.append(tupNew)\n",
    "\n",
    "\n",
    "    total_task_num=len(protParamListNew)\n",
    "    pool = Pool()\n",
    "    similarity_listRet = []\n",
    "    for similarity_listRet in tqdm_notebook(pool.imap_unordered(parallelSimilarity, protParamListNew), total=total_task_num):\n",
    "        pass\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    real_distance_list = [value[0] for value in similarity_listRet]\n",
    "    cosine_distance_list = [value[1] for value in similarity_listRet]\n",
    "    manhattan_distance_list = [value[2] for value in similarity_listRet]\n",
    "    euclidian_distance_list = [value[3] for value in similarity_listRet]\n",
    "\n",
    "    #mseValue = mse(real_distance_list,cosine_distance_list)\n",
    "    cosineCorr = spearmanr(real_distance_list, cosine_distance_list)\n",
    "    manhattanCorr = spearmanr(real_distance_list, manhattan_distance_list)\n",
    "    euclidianCorr = spearmanr(real_distance_list, euclidian_distance_list)\n",
    "\n",
    "    random.seed(42)\n",
    "    random_list = []\n",
    "    for i in range(len(real_distance_list)):\n",
    "        random_list.append(random.uniform(0, 1))\n",
    "    \n",
    "    if sparse:\n",
    "        cosine_randomCorr = spearmanr(cosine_distance_list, random_list)\n",
    "        manhattan_randomCorr = spearmanr(manhattan_distance_list, random_list)\n",
    "        euclidian_randomCorr = spearmanr(euclidian_distance_list, random_list)\n",
    "        print(\"Cosine Random Correlation for \"+aspect+\" is \" + str(cosine_randomCorr))\n",
    "        print(\"Manhattan Random Correlation for \"+aspect+\" is \" + str(manhattan_randomCorr))\n",
    "        print(\"Euclidian Random Correlation for \"+aspect+\" is \" + str(euclidian_randomCorr))\n",
    "    \n",
    "    \n",
    "    print(\"Cosine Correlation for \"+aspect+\" is \" + str(cosineCorr))\n",
    "    print(\"Manhattan Correlation for \"+aspect+\" is \" + str(manhattanCorr))\n",
    "    print(\"Euclidian Correlation for \"+aspect+\" is \" + str(euclidianCorr))\n",
    "\n",
    "    if sparse:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr,cosine_randomCorr,manhattan_randomCorr,euclidian_randomCorr)\n",
    "    else:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Normal Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae05bb3c74d24284a0a5410ca3371731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a319237980446f8de5ff134a565415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for MF is SpearmanrResult(correlation=-0.20664982255238126, pvalue=7.638675917122441e-178)\n",
      "Manhattan Correlation for MF is SpearmanrResult(correlation=0.19279289122553758, pvalue=1.2769773912789466e-154)\n",
      "Euclidian Correlation for MF is SpearmanrResult(correlation=0.20664982255238126, pvalue=7.638675917122441e-178)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29e82c9084e413e87763b8ed73b7194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad33b0f816140539b4a7d2dafc4507e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for BP is SpearmanrResult(correlation=-0.2586085107136244, pvalue=1.5272830050960912e-266)\n",
      "Manhattan Correlation for BP is SpearmanrResult(correlation=0.24968551219897236, pvalue=5.069595486252185e-248)\n",
      "Euclidian Correlation for BP is SpearmanrResult(correlation=0.2586085107136244, pvalue=1.5272830050960912e-266)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a9678d5c774f658ce40b30bfd44417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424a87e71c514d7d80c56a022b9ce095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for CC is SpearmanrResult(correlation=-0.10479894789959376, pvalue=6.045123802331219e-46)\n",
      "Manhattan Correlation for CC is SpearmanrResult(correlation=0.09861306676873008, pvalue=7.403060708066283e-41)\n",
      "Euclidian Correlation for CC is SpearmanrResult(correlation=0.10479894789959376, pvalue=6.045123802331219e-46)\n"
     ]
    }
   ],
   "source": [
    "buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal \\n\"\n",
    "#saveFileName = \"SimilarityMut2Vec.csv\"\n",
    "saveFileName = \"SimilarityMut2Vec_highest_200.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect) \n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    ## Python will convert \\n to os.linesep\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "# MF    0.1866509691526721\n",
    "# BP    0.3116883116883117\n",
    "# CC   -0.2711730421384723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Sparse Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal,random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\\n#saveFileName = \"SimilarityGene2Vec.csv\"\\nsaveFileName = \"Similarity_Sparse_Mut2Vec_highest_500.csv\"\\nf = open(saveFileName,\\'w\\')\\nf.write(buffer)\\n\\nfor aspect in [\"MF\",\"BP\",\"CC\"]:\\n    corr = calculateMSEforOntology(aspect,True) \\n    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \\n    f = open(saveFileName,\\'a\\')\\n    f.write(buffer) #Give your csv text here.\\n    ## Python will convert \\n to os.linesep\\n    f.close()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal\\\n",
    ",random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\n",
    "#saveFileName = \"SimilarityGene2Vec.csv\"\n",
    "saveFileName = \"Similarity_Sparse_Mut2Vec_highest_500.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect,True) \n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    ## Python will convert \\n to os.linesep\n",
    "    f.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
