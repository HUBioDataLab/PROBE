{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates similarity and error between protein embeddings and use GO semantic similarity as gold standart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from multiprocessing import Manager, Pool\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"\\\n",
    "    +\"CC\"+\"_proteinSimilarityMatrix_for_highest_annotated_200_proteins.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_proteinSimilarityMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load protein vectors of ProtVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protVecFile = gzip.GzipFile('/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/ProtVec/calculated_human_protein_vectors.npy.gz', \"r\")\n",
    "protVecEmbeddingDict = np.load(protVecFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIPROT data for mapping between UNIPROT accession numbers and UNIPROT entry names\n",
    "uniprot_metadata_directory = \"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/Uniprot/\"\n",
    "uniprot_metadata_file_path = uniprot_metadata_directory + \"uniprot_human_all.tab\"\n",
    "uniprot_vars = ['Entry','Entry name','Status','Protein names','Gene names','Organism','Length','Annotation' ]\n",
    "uniprot_df = pd.read_csv(uniprot_metadata_file_path, sep='\\t', header=None, names=uniprot_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1686b432736447da612e412bc62a8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20422), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01892\n",
      "Empty DataFrame\n",
      "Columns: [Entry, Entry name, Status, Protein names, Gene names, Organism, Length, Annotation]\n",
      "Index: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "protVecDF = pd.DataFrame(columns=['Entry', 'Vector'])\n",
    "i=0\n",
    "for entry_name,vector in tqdm_notebook(protVecEmbeddingDict[()].items()):\n",
    "    try:\n",
    "        if len(vector) != 100:\n",
    "            print(\"Size exception\")\n",
    "            print(entry_name)\n",
    "            print(len(vector))\n",
    "        entry = uniprot_df[uniprot_df['Entry name'] == entry_name]['Entry'].item()\n",
    "        protVecDF.loc[i] = [entry,vector]\n",
    "        i+=1\n",
    "    except:\n",
    "        print(entry_name)\n",
    "        print(uniprot_df[uniprot_df['Entry name'] == entry_name])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in protVecDF['Vector']:\n",
    "    if len(vec) != 100:\n",
    "        print(len(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "protVecDF.to_pickle(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/embedding_dataframes/protVec_dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "protVecDF.to_csv(\"/media/DATA/serbulent/DATA/Thesis/ReviewPaper/results/embedding_dataframes/protVec_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#This part was used to be sure parallel and sequential versions gives same results\\ncosine_distance_list1 = []\\nreal_distance_list1 = []\\n\\nsimilarityMatrixFileName = \"\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\\nsimilarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\\n\\nhuman_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\\nhuman_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\\n\\nproteinListTmp = human_protienSimilarityMatrix.columns[0:10] \\nfor i,protein1 in enumerate(proteinListTmp):\\n    for j in range(len(proteinListTmp)):\\n        if j>i:\\n            protein2 = proteinListTmp[j]\\n            prot1name = uniprot_df.query(\"Entry == @protein1\")[\\'Entry name\\'].item()\\n            prot2name = uniprot_df.query(\"Entry == @protein2\")[\\'Entry name\\'].item()\\n            prot1vec = protVecEmbeddingDict[()][prot1name]\\n            prot2vec = protVecEmbeddingDict[()][prot2name]\\n            #cosine will return in shape of input vectors first dimension\\n            cosine_distance_list1.append(cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item())\\n            real_distance_list1.append(human_protienSimilarityMatrix.loc[protein1,protein2])\\n\\nprint(mse(real_distance_list1,cosine_distance_list1))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#This part was used to be sure parallel and sequential versions gives same results\n",
    "cosine_distance_list1 = []\n",
    "real_distance_list1 = []\n",
    "\n",
    "similarityMatrixFileName = \"\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_BP_protienSimilarityMatrix.csv\"\n",
    "similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_CC_protienSimilarityMatrix.csv\"\n",
    "\n",
    "human_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "human_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\n",
    "\n",
    "proteinListTmp = human_protienSimilarityMatrix.columns[0:10] \n",
    "for i,protein1 in enumerate(proteinListTmp):\n",
    "    for j in range(len(proteinListTmp)):\n",
    "        if j>i:\n",
    "            protein2 = proteinListTmp[j]\n",
    "            prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "            prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()\n",
    "            prot1vec = protVecEmbeddingDict[()][prot1name]\n",
    "            prot2vec = protVecEmbeddingDict[()][prot2name]\n",
    "            #cosine will return in shape of input vectors first dimension\n",
    "            cosine_distance_list1.append(cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item())\n",
    "            real_distance_list1.append(human_protienSimilarityMatrix.loc[protein1,protein2])\n",
    "\n",
    "print(mse(real_distance_list1,cosine_distance_list1))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Multiprocess check\\nproteinList = []\\nmanager = Manager()\\nsimilarity_list = manager.list()\\n\\ndef parallelSimilarity(paramList):\\n    #print(paramList)\\n    i = paramList[0]\\n    j = paramList[1]\\n    if j>i:  \\n        protein1 = proteinList[i]\\n        protein2 = proteinList[j]\\n        prot1name = uniprot_df.query(\"Entry == @protein1\")[\\'Entry name\\'].item()\\n        prot2name = uniprot_df.query(\"Entry == @protein2\")[\\'Entry name\\'].item()\\n        prot1vec = protVecEmbeddingDict[()][prot1name]\\n        prot2vec = protVecEmbeddingDict[()][prot2name]\\n        #cosine will return in shape of input vectors first dimension\\n        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\\n        real = human_protienSimilarityMatrix.loc[protein1,protein2]\\n        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\\n        similarity_list.append((real,cos))\\n\\n#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\\nsimilarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\\n\\nhuman_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\\nhuman_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\\nproteinList = human_protienSimilarityMatrix.columns[0:10]\\n\\ni = range(len(proteinList))\\nj = range(len(proteinList))\\nprotParamList = list(itertools.product(i,j))\\n\\n    #manager = Manager()\\n    #similarity_list = manager.list()\\ntotal_task_num=len(proteinList)**2\\n\\npool = Pool()\\npool.map(parallelSimilarity, protParamList)\\npool.close()\\npool.join()\\n\\nreal_distance_list = [value[0] for value in similarity_list]\\ncosine_distance_list = [value[1] for value in similarity_list]\\n\\nmseValue = mse(real_distance_list,cosine_distance_list)\\nprint(mseValue)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Multiprocess check\n",
    "proteinList = []\n",
    "manager = Manager()\n",
    "similarity_list = manager.list()\n",
    "\n",
    "def parallelSimilarity(paramList):\n",
    "    #print(paramList)\n",
    "    i = paramList[0]\n",
    "    j = paramList[1]\n",
    "    if j>i:  \n",
    "        protein1 = proteinList[i]\n",
    "        protein2 = proteinList[j]\n",
    "        prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "        prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()\n",
    "        prot1vec = protVecEmbeddingDict[()][prot1name]\n",
    "        prot2vec = protVecEmbeddingDict[()][prot2name]\n",
    "        #cosine will return in shape of input vectors first dimension\n",
    "        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "        real = human_protienSimilarityMatrix.loc[protein1,protein2]\n",
    "        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\n",
    "        similarity_list.append((real,cos))\n",
    "\n",
    "#similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\n",
    "similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_MF_protienSimilarityMatrix.csv\"\n",
    "\n",
    "human_protienSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "human_protienSimilarityMatrix.set_index(human_protienSimilarityMatrix.columns, inplace = True)\n",
    "proteinList = human_protienSimilarityMatrix.columns[0:10]\n",
    "\n",
    "i = range(len(proteinList))\n",
    "j = range(len(proteinList))\n",
    "protParamList = list(itertools.product(i,j))\n",
    "\n",
    "    #manager = Manager()\n",
    "    #similarity_list = manager.list()\n",
    "total_task_num=len(proteinList)**2\n",
    "\n",
    "pool = Pool()\n",
    "pool.map(parallelSimilarity, protParamList)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "real_distance_list = [value[0] for value in similarity_list]\n",
    "cosine_distance_list = [value[1] for value in similarity_list]\n",
    "\n",
    "mseValue = mse(real_distance_list,cosine_distance_list)\n",
    "print(mseValue)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity_list and proteinList as global variables\n",
    "proteinList = []\n",
    "manager = Manager()\n",
    "similarity_list = manager.list()\n",
    "proteinListNew = manager.list()\n",
    "\n",
    "def parallelSimilarity(paramList):\n",
    "    i = paramList[0]\n",
    "    j = paramList[1] \n",
    "    aspect = paramList[2]\n",
    "\n",
    "    if j>i:\n",
    "        protein1 = proteinListNew[i]\n",
    "        protein2 = proteinListNew[j]\n",
    "        prot1name = uniprot_df.query(\"Entry == @protein1\")['Entry name'].item()\n",
    "        prot2name = uniprot_df.query(\"Entry == @protein2\")['Entry name'].item()\n",
    "        prot1vec = protVecEmbeddingDict[()][prot1name]\n",
    "        prot2vec = protVecEmbeddingDict[()][prot2name]\n",
    "        #cosine will return in shape of input vectors first dimension\n",
    "        #print(str(prot1name) + str(prot1vec))\n",
    "        #print(str(prot2name) + str(prot2vec))\n",
    "        cos = cosine(prot1vec.reshape(1,-1),prot2vec.reshape(1,-1)).item()\n",
    "        manhattanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'cityblock')\n",
    "        manhattanDistNorm = manhattanDist/(norm(prot1vec,1) + norm(prot2vec,1))\n",
    "        euclideanDist = cdist(prot1vec.reshape(1,-1), prot2vec.reshape(1,-1), 'euclidean')\n",
    "        euclideanDistNorm = euclideanDist/(norm(prot1vec,2) + norm(prot2vec,2)) \n",
    "        real = paramList[3]\n",
    "        #real = human_protienSimilarityMatrix.loc[protein1,protein2]\n",
    "        # To ensure real and calculated values appended to same postion they saved similtanously and then decoupled\n",
    "        similarity_list.append((real,1-cos,1-manhattanDistNorm.item(),1-euclideanDistNorm.item()))\n",
    "    return similarity_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity values with parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMSEforOntology(aspect,sparse=False):\n",
    "    \n",
    "    #Clear lists before each aspect\n",
    "    similarity_list[:] = []\n",
    "    proteinListNew[:] = []\n",
    "\n",
    "    #similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"+aspect+\"_protienSimilarityMatrix.csv\"\n",
    "    similarityMatrixFileName = \"/media/DATA/serbulent/Code/Thesis/ReviewPaper/preprocess/human_\"\\\n",
    "    +aspect+\"_proteinSimilarityMatrix_for_highest_annotated_200_proteins.csv\"\n",
    "\n",
    "    \n",
    "    human_proteinSimilarityMatrix = pd.read_csv(similarityMatrixFileName)\n",
    "    human_proteinSimilarityMatrix.set_index(human_proteinSimilarityMatrix.columns, inplace = True)\n",
    "    #proteinList = human_proteinSimilarityMatrix\n",
    "    proteinList = human_proteinSimilarityMatrix.columns\n",
    "    \n",
    "     #proteinListNew is referanced using Manager\n",
    "    for prot in proteinList:\n",
    "        proteinListNew.append(prot)\n",
    "    if sparse:\n",
    "        #sparsified_similarities = np.load(\"SparsifiedSimilarites_for_highest_500.npy\")\n",
    "        sparsified_similarity_coordinates = np.load(\"SparsifiedSimilarityCoordinates_\"+aspect+\"_for_highest_500.npy\")\n",
    "        protParamList = sparsified_similarity_coordinates\n",
    "    else:     \n",
    "        i = range(len(proteinList))\n",
    "        j = range(len(proteinList))\n",
    "        protParamList = list(itertools.product(i,j))\n",
    "    protParamListNew = []\n",
    "    # Prepare parameters for parallel processing these parameters will be \n",
    "    # used concurrently by different processes\n",
    "    for tup in tqdm_notebook(protParamList):\n",
    "        i = tup[0]\n",
    "        j = tup[1]\n",
    "        \n",
    "        if sparse:\n",
    "            protein1 = proteinListNew[i]\n",
    "            protein2 = proteinListNew[j]\n",
    "            real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "            tupNew = (tup[0],tup[1],aspect,real)\n",
    "            protParamListNew.append(tupNew)\n",
    "        else:\n",
    "            if j > i:\n",
    "                protein1 = proteinListNew[i]\n",
    "                protein2 = proteinListNew[j]\n",
    "                real = human_proteinSimilarityMatrix.loc[protein1,protein2]\n",
    "                tupNew = (tup[0],tup[1],aspect,real)\n",
    "                protParamListNew.append(tupNew)\n",
    "\n",
    "    total_task_num=len(protParamListNew)\n",
    "    pool = Pool()\n",
    "    similarity_listRet = []\n",
    "    for similarity_listRet in tqdm_notebook(pool.imap_unordered(parallelSimilarity, protParamListNew), total=total_task_num):\n",
    "        pass\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    real_distance_list = [value[0] for value in similarity_listRet]\n",
    "    cosine_distance_list = [value[1] for value in similarity_listRet]\n",
    "    manhattan_distance_list = [value[2] for value in similarity_listRet]\n",
    "    euclidian_distance_list = [value[3] for value in similarity_listRet]\n",
    "\n",
    "    #mseValue = mse(real_distance_list,cosine_distance_list)\n",
    "    cosineCorr = spearmanr(real_distance_list, cosine_distance_list)\n",
    "    manhattanCorr = spearmanr(real_distance_list, manhattan_distance_list)\n",
    "    euclidianCorr = spearmanr(real_distance_list, euclidian_distance_list)\n",
    "    \n",
    "    random.seed(42)\n",
    "    random_list = []\n",
    "    for i in range(len(real_distance_list)):\n",
    "        random_list.append(random.uniform(0, 1))\n",
    "    \n",
    "    if sparse:\n",
    "        cosine_randomCorr = spearmanr(cosine_distance_list, random_list)\n",
    "        manhattan_randomCorr = spearmanr(manhattan_distance_list, random_list)\n",
    "        euclidian_randomCorr = spearmanr(euclidian_distance_list, random_list)\n",
    "        print(\"Cosine Random Correlation for \"+aspect+\" is \" + str(cosine_randomCorr))\n",
    "        print(\"Manhattan Random Correlation for \"+aspect+\" is \" + str(manhattan_randomCorr))\n",
    "        print(\"Euclidian Random Correlation for \"+aspect+\" is \" + str(euclidian_randomCorr))\n",
    "    \n",
    "    \n",
    "    print(\"Cosine Correlation for \"+aspect+\" is \" + str(cosineCorr))\n",
    "    print(\"Manhattan Correlation for \"+aspect+\" is \" + str(manhattanCorr))\n",
    "    print(\"Euclidian Correlation for \"+aspect+\" is \" + str(euclidianCorr))\n",
    "\n",
    "    if sparse:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr,cosine_randomCorr,manhattan_randomCorr,euclidian_randomCorr)\n",
    "    else:\n",
    "        return (cosineCorr,manhattanCorr,euclidianCorr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faeff523b6c54da2b22a0f62d12cd3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03a06b0d9c14a84b37a891f06b21b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for MF is SpearmanrResult(correlation=-0.02631840171325433, pvalue=0.0002047542857679604)\n",
      "Manhattan Correlation for MF is SpearmanrResult(correlation=0.08097384767506213, pvalue=2.6134536449824976e-30)\n",
      "Euclidian Correlation for MF is SpearmanrResult(correlation=0.08288474325035798, pvalue=1.109619961090317e-31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf94ccd51734c04ac343b7aa98e4868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d02fb461b8f4881acb50e2c12f01492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for BP is SpearmanrResult(correlation=-0.03662264288717128, pvalue=2.3703231046938388e-07)\n",
      "Manhattan Correlation for BP is SpearmanrResult(correlation=0.08312061352119392, pvalue=7.47480595371219e-32)\n",
      "Euclidian Correlation for BP is SpearmanrResult(correlation=0.08437288744151857, pvalue=9.005691295013815e-33)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d9c8b124d84b12889e96d9c64b9fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0395f629bf4450eb900c92a649d1339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Correlation for CC is SpearmanrResult(correlation=-0.07048255781813766, pvalue=2.4092284708430528e-23)\n",
      "Manhattan Correlation for CC is SpearmanrResult(correlation=0.07242533908546427, pvalue=1.4605386494772896e-24)\n",
      "Euclidian Correlation for CC is SpearmanrResult(correlation=0.07168915481034553, pvalue=4.2626027668260024e-24)\n"
     ]
    }
   ],
   "source": [
    "buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal \\n\"\n",
    "saveFileName = \"tmp_CC_SimilarityProtVec_highest_200.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect) \n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    ## Python will convert \\n to os.linesep\n",
    "    f.close()\n",
    "    \n",
    "# 0.3673674654105104 mse for MF with 0:10\n",
    "# 0.31965355246378196 mse for BP with 0:10\n",
    "# 0.29460915219361683 mse for CC with 0:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal,random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\\n#saveFileName = \"SimilarityGene2Vec.csv\"\\nsaveFileName = \"Similarity_Sparse_ProtVec_highest_500.csv\"\\nf = open(saveFileName,\\'w\\')\\nf.write(buffer)\\n\\nfor aspect in [\"MF\",\"BP\",\"CC\"]:\\n    corr = calculateMSEforOntology(aspect,True) \\n    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \\n    f = open(saveFileName,\\'a\\')\\n    f.write(buffer) #Give your csv text here.\\n    ## Python will convert \\n to os.linesep\\n    f.close()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''buffer = \"aspect,cosineCorr,cosineCorrPVal,manhattanCorr,manhattanCorrPVal,euclidianCorr,euclidianCorrPVal\\\n",
    ",random_cosineCorr,random_cosineCorrPVal,random_manhattanCorr,random_manhattanCorrPVal,random_euclidianCorr,random_euclidianCorrPVal\\n\"\n",
    "#saveFileName = \"SimilarityGene2Vec.csv\"\n",
    "saveFileName = \"Similarity_Sparse_ProtVec_highest_500.csv\"\n",
    "f = open(saveFileName,'w')\n",
    "f.write(buffer)\n",
    "\n",
    "for aspect in [\"MF\",\"BP\",\"CC\"]:\n",
    "    corr = calculateMSEforOntology(aspect,True) \n",
    "    buffer = \"\" + aspect + \",\"+ str(corr[0][0])+ \",\"+ str(corr[0][1])\\\n",
    "    + \",\"+ str(corr[1][0])+ \",\"+ str(corr[1][1])+ \",\"+ str(corr[2][0])+ \",\"+ str(corr[2][1])+\"\\n\" \n",
    "    f = open(saveFileName,'a')\n",
    "    f.write(buffer) #Give your csv text here.\n",
    "    ## Python will convert \\n to os.linesep\n",
    "    f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
